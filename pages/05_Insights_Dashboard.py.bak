import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime
import json
from utils.ai_suggestions import generate_dataset_insights, answer_data_question
from utils.visualization import create_visualization_from_suggestion
from utils.auth_redirect import require_auth

st.set_page_config(
    page_title="Insights Dashboard | Analytics Assist",
    page_icon="ðŸ’¡",
    layout="wide"
)
# Initialize navigation
initialize_navigation()

# Hide Streamlitâ€™s default multipage navigation menu
st.markdown("""
    <style>
        [data-testid="stSidebarNav"] {
            display: none !important;
        }
    </style>
""", unsafe_allow_html=True)
# Render custom navigation bar
render_navigation()
# Check authentication first
if not require_auth():
    st.stop()  # Stop if not authenticated

# Show user info if authenticated
if "user" in st.session_state:
    st.sidebar.success(f"Logged in as: {st.session_state.user.get('email', 'User')}")
    st.sidebar.info(f"Subscription: {st.session_state.subscription_tier.capitalize()}")

# Check if dataset exists in session state
if 'dataset' not in st.session_state or st.session_state.dataset is None:
    st.warning("Please upload a dataset first.")
    st.button("Go to Upload Page", on_click=lambda: st.switch_page("pages/01_Upload_Data.py"))
    st.stop()

# Header and description
st.title("AI-Generated Insights Dashboard")
st.markdown("""
Discover valuable insights about your data automatically generated by our AI.
These insights highlight key findings, patterns, and anomalies in your dataset.
""")

# Get data from session state
df = st.session_state.dataset

# Initialize insights in session state if they don't exist
if 'insights' not in st.session_state:
    st.session_state.insights = []

# Create tabs for different insights sections
tab1, tab2, tab3 = st.tabs([
    "ðŸ’¡ Key Insights", 
    "ðŸ”Ž Ask Questions", 
    "ðŸ§  Custom Analysis"
])

# Tab 1: Key Insights
with tab1:
    st.subheader("AI-Generated Data Insights")
    
    # Button to generate insights
    if not st.session_state.insights:
        if st.button("Generate AI Insights"):
            with st.spinner("Analyzing your data and generating insights..."):
                # Generate insights using AI
                insights = generate_dataset_insights(df)
                
                if insights:
                    # Store insights in session state
                    st.session_state.insights = insights
                    st.success(f"Successfully generated {len(insights)} insights!")
                    st.rerun()
                else:
                    st.error("Failed to generate insights. Please try again.")
    else:
        # Display existing insights
        insights = st.session_state.insights
        
        # Display insights by importance (highest first)
        sorted_insights = sorted(insights, key=lambda x: x.get('importance', 0), reverse=True)
        
        for i, insight in enumerate(sorted_insights):
            # Create a card-like display for each insight
            with st.container():
                st.markdown(f"### {i+1}. {insight.get('title', 'Insight')}")
                
                # Show importance as stars
                importance = insight.get('importance', 3)
                st.markdown(f"**Importance:** {'â­' * importance}")
                
                # Display insight type
                insight_type = insight.get('type', 'general')
                st.markdown(f"**Type:** {insight_type.title()}")
                
                # Description
                st.markdown(f"{insight.get('description', 'No description available')}")
                
                # Recommended action
                if 'recommended_action' in insight and insight['recommended_action']:
                    st.markdown(f"**Recommended Action:** {insight['recommended_action']}")
                
                # Generate visualization for certain insight types if possible
                if insight_type in ['correlation', 'distribution', 'outlier', 'trend']:
                    # Extract relevant columns from insight
                    columns = []
                    if 'relevant_columns' in insight:
                        columns = insight['relevant_columns']
                    elif 'columns' in insight:
                        columns = insight['columns']
                    else:
                        # Try to extract column names from the description
                        import re
                        col_matches = re.findall(r'\'([^\']+)\'', insight['description'])
                        columns = [col for col in col_matches if col in df.columns]
                    
                    if columns and len(columns) > 0:
                        # Create a suggested visualization based on insight type
                        suggestion = {
                            'chart_type': 'histogram' if insight_type == 'distribution' else
                                         'scatter_plot' if insight_type == 'correlation' else
                                         'box_plot' if insight_type == 'outlier' else
                                         'line_chart' if insight_type == 'trend' else
                                         'bar_chart',
                            'columns': columns[:min(3, len(columns))],
                            'title': insight.get('title', 'Visualization')
                        }
                        
                        fig = create_visualization_from_suggestion(df, suggestion)
                        if fig:
                            st.plotly_chart(fig, use_container_width=True, key=f"insight_vis_{i}_{insight_type}")
                
                st.markdown("---")
        
        # Button to regenerate insights
        if st.button("Regenerate Insights"):
            with st.spinner("Regenerating insights..."):
                # Generate new insights
                new_insights = generate_dataset_insights(df)
                
                if new_insights:
                    # Store new insights in session state
                    st.session_state.insights = new_insights
                    st.success(f"Successfully regenerated {len(new_insights)} insights!")
                    st.rerun()
                else:
                    st.error("Failed to regenerate insights. Please try again.")

# Tab 2: Ask Questions
with tab2:
    st.subheader("Ask Questions About Your Data")
    st.markdown("""
    Ask natural language questions about your data, and our AI will analyze and answer them.
    For example, you can ask:
    - "What's the average value of [column]?"
    - "Is there a correlation between [column1] and [column2]?"
    - "What are the top 5 values in [column]?"
    - "How many missing values are there in each column?"
    """)
    
    # Text input for question
    question = st.text_input("Enter your question:", placeholder="e.g., What are the top values in [column]?")
    
    # Process question when submitted
    if question:
        if st.button("Get Answer"):
            with st.spinner("Analyzing your question..."):
                # Get answer from AI
                answer_data = answer_data_question(df, question)
                
                if answer_data and 'answer' in answer_data:
                    # Display answer
                    st.markdown("### Answer")
                    st.markdown(answer_data['answer'])
                    
                    # Show confidence if available
                    if 'confidence' in answer_data:
                        try:
                            confidence = float(answer_data['confidence'])
                            confidence_color = 'green' if confidence > 0.8 else 'orange' if confidence > 0.5 else 'red'
                            st.markdown(f"**Confidence:** <span style='color:{confidence_color}'>{confidence:.0%}</span>", unsafe_allow_html=True)
                        except (TypeError, ValueError):
                            # If confidence can't be converted to float, just display it as is
                            st.markdown(f"**Confidence:** {answer_data['confidence']}")
                    
                    # Show visualization if suggested
                    if 'suggested_visualization' in answer_data and answer_data['suggested_visualization']:
                        st.markdown("### Suggested Visualization")
                        
                        # Extract columns based on relevant columns mentioned
                        if 'relevant_columns' in answer_data and answer_data['relevant_columns']:
                            relevant_columns = [col for col in answer_data['relevant_columns'] if col in df.columns]
                            
                            if relevant_columns:
                                # Determine the chart type based on the data and question
                                is_time_series = any(pd.api.types.is_datetime64_dtype(df[col]) for col in relevant_columns)
                                is_categorical = any(df[col].dtype == 'object' for col in relevant_columns if col in df.columns)
                                is_correlation = 'correlation' in question.lower() or 'relationship' in question.lower()
                                
                                if is_correlation and len(relevant_columns) >= 2:
                                    # Create scatter plot for correlations
                                    suggestion = {
                                        'chart_type': 'scatter_plot',
                                        'columns': relevant_columns[:2],
                                        'title': f"Relationship between {relevant_columns[0]} and {relevant_columns[1]}"
                                    }
                                elif is_time_series:
                                    # Create time series plot
                                    date_col = next(col for col in relevant_columns if pd.api.types.is_datetime64_dtype(df[col]))
                                    numeric_cols = [col for col in relevant_columns if pd.api.types.is_numeric_dtype(df[col])]
                                    
                                    if date_col and numeric_cols:
                                        suggestion = {
                                            'chart_type': 'line_chart',
                                            'columns': [date_col, numeric_cols[0]],
                                            'title': f"{numeric_cols[0]} over time"
                                        }
                                    else:
                                        suggestion = None
                                elif is_categorical and any(pd.api.types.is_numeric_dtype(df[col]) for col in relevant_columns if col in df.columns):
                                    # Create bar chart for categorical data
                                    cat_col = next(col for col in relevant_columns if df[col].dtype == 'object')
                                    numeric_col = next(col for col in relevant_columns if pd.api.types.is_numeric_dtype(df[col]))
                                    
                                    suggestion = {
                                        'chart_type': 'bar_chart',
                                        'columns': [cat_col],
                                        'title': f"Distribution of {cat_col}"
                                    }
                                elif any(pd.api.types.is_numeric_dtype(df[col]) for col in relevant_columns if col in df.columns):
                                    # Create histogram for numeric data
                                    numeric_col = next(col for col in relevant_columns if pd.api.types.is_numeric_dtype(df[col]))
                                    
                                    suggestion = {
                                        'chart_type': 'histogram',
                                        'columns': [numeric_col],
                                        'title': f"Distribution of {numeric_col}"
                                    }
                                else:
                                    suggestion = None
                                
                                # Create and display the visualization
                                if suggestion:
                                    fig = create_visualization_from_suggestion(df, suggestion)
                                    if fig:
                                        st.plotly_chart(fig, use_container_width=True, key=f"answer_vis_{suggestion['chart_type']}")
                else:
                    st.error("Failed to get an answer. Please try rephrasing your question.")
    
    # Example questions
    with st.expander("Example Questions"):
        example_questions = [
            "What is the average of [NUMERIC_COLUMN]?",
            "What is the distribution of [CATEGORICAL_COLUMN]?",
            "Is there a correlation between [NUMERIC_COLUMN1] and [NUMERIC_COLUMN2]?",
            "What are the top 5 values in [COLUMN]?",
            "How many missing values are there in each column?",
            "Which columns have the most outliers?",
            "What is the trend of [NUMERIC_COLUMN] over time?",
            "What is the most common value in [CATEGORICAL_COLUMN]?"
        ]
        
        # Replace placeholders with actual column names where possible
        if df is not None:
            numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
            cat_cols = df.select_dtypes(include=['object']).columns.tolist()
            date_cols = df.select_dtypes(include=['datetime']).columns.tolist()
            
            for i, question in enumerate(example_questions):
                if "[NUMERIC_COLUMN]" in question and numeric_cols:
                    example_questions[i] = question.replace("[NUMERIC_COLUMN]", numeric_cols[0])
                if "[NUMERIC_COLUMN1]" in question and len(numeric_cols) > 0:
                    example_questions[i] = question.replace("[NUMERIC_COLUMN1]", numeric_cols[0])
                if "[NUMERIC_COLUMN2]" in question and len(numeric_cols) > 1:
                    example_questions[i] = question.replace("[NUMERIC_COLUMN2]", numeric_cols[1])
                if "[CATEGORICAL_COLUMN]" in question and cat_cols:
                    example_questions[i] = question.replace("[CATEGORICAL_COLUMN]", cat_cols[0])
                if "[COLUMN]" in question and df.columns.tolist():
                    example_questions[i] = question.replace("[COLUMN]", df.columns[0])
        
        for question in example_questions:
            if st.button(question, key=f"example_{question}"):
                st.session_state.example_question = question
                st.rerun()

# Tab 3: Custom Analysis
with tab3:
    st.subheader("Custom Analysis")
    st.markdown("""
    Perform custom analyses on your data by specifying variables and analysis types.
    This allows you to dive deeper into specific aspects of your dataset.
    """)
    
    # Analysis type selection
    analysis_type = st.selectbox(
        "Select Analysis Type",
        [
            "Variable Summary",
            "Relationship Analysis",
            "Group Comparison",
            "Time Series Decomposition"
        ]
    )
    
    # Variable Summary
    if analysis_type == "Variable Summary":
        # Select a column to analyze
        column = st.selectbox("Select column to analyze", df.columns.tolist())
        
        if column:
            st.markdown(f"### Summary of {column}")
            
            # Different analysis based on data type
            if pd.api.types.is_numeric_dtype(df[column]):
                # Numeric column
                
                # Show basic stats
                stats = df[column].describe()
                st.write(stats)
                
                # Create visualizations
                col1, col2 = st.columns(2)
                
                with col1:
                    # Histogram
                    fig_hist = px.histogram(
                        df, 
                        x=column,
                        title=f"Distribution of {column}",
                        color_discrete_sequence=['#4F8BF9'],
                        marginal='box'
                    )
                    st.plotly_chart(fig_hist, use_container_width=True)
                
                with col2:
                    # Box plot
                    fig_box = px.box(
                        df,
                        y=column,
                        title=f"Box Plot of {column}",
                        color_discrete_sequence=['#4F8BF9']
                    )
                    st.plotly_chart(fig_box, use_container_width=True)
                
                # Additional insights
                st.markdown("### Additional Insights")
                
                # Calculate skewness and kurtosis
                skewness = df[column].skew()
                kurtosis = df[column].kurt()
                
                st.markdown(f"**Skewness:** {skewness:.4f}")
                if abs(skewness) > 1:
                    st.markdown("The distribution is highly skewed. Consider applying a transformation.")
                elif abs(skewness) > 0.5:
                    st.markdown("The distribution is moderately skewed.")
                else:
                    st.markdown("The distribution is approximately symmetric.")
                
                st.markdown(f"**Kurtosis:** {kurtosis:.4f}")
                if kurtosis > 3:
                    st.markdown("The distribution has heavy tails (more outliers than normal distribution).")
                elif kurtosis < 3:
                    st.markdown("The distribution has light tails (fewer outliers than normal distribution).")
                else:
                    st.markdown("The distribution has similar tails to a normal distribution.")
                
                # Normality test
                from scipy import stats as scipy_stats
                stat, p_value = scipy_stats.normaltest(df[column].dropna())
                
                st.markdown(f"**Normality Test p-value:** {p_value:.4f}")
                if p_value < 0.05:
                    st.markdown("The distribution is significantly different from normal.")
                else:
                    st.markdown("The distribution is not significantly different from normal.")
                
            elif pd.api.types.is_datetime64_dtype(df[column]):
                # Datetime column
                
                # Show basic stats
                st.write(f"**Min date:** {df[column].min()}")
                st.write(f"**Max date:** {df[column].max()}")
                st.write(f"**Range:** {(df[column].max() - df[column].min()).days} days")
                
                # Create time distribution
                fig_time = px.histogram(
                    df,
                    x=column,
                    title=f"Distribution over time for {column}",
                    color_discrete_sequence=['#4F8BF9']
                )
                st.plotly_chart(fig_time, use_container_width=True)
                
                # Extract components
                st.markdown("### Date Components")
                
                df_time = df.copy()
                df_time['year'] = df[column].dt.year
                df_time['month'] = df[column].dt.month
                df_time['day'] = df[column].dt.day
                df_time['day_of_week'] = df[column].dt.day_name()
                
                # Show distribution by components
                col1, col2 = st.columns(2)
                
                with col1:
                    # Month distribution
                    month_counts = df_time['month'].value_counts().sort_index()
                    # Create a complete set of months (1-12) with zeros for missing months
                    all_months = list(range(1, 13))
                    month_values = [month_counts.get(m, 0) for m in all_months]
                    month_labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
                    
                    fig_month = px.bar(
                        x=month_labels,
                        y=month_values,
                        title="Distribution by Month",
                        color_discrete_sequence=['#4F8BF9']
                    )
                    st.plotly_chart(fig_month, use_container_width=True)
                
                with col2:
                    # Day of week distribution
                    dow_counts = df_time['day_of_week'].value_counts()
                    # Sort by day of week
                    days_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
                    dow_counts = dow_counts.reindex(days_order)
                    
                    fig_dow = px.bar(
                        x=dow_counts.index,
                        y=dow_counts.values,
                        title="Distribution by Day of Week",
                        color_discrete_sequence=['#4F8BF9']
                    )
                    st.plotly_chart(fig_dow, use_container_width=True)
                
            else:
                # Categorical/Text column
                
                # Show value counts
                value_counts = df[column].value_counts().reset_index()
                value_counts.columns = [column, 'Count']
                
                # Add percentage
                value_counts['Percentage'] = (value_counts['Count'] / value_counts['Count'].sum() * 100).round(2)
                
                # Display top values
                if len(value_counts) > 10:
                    st.write("Top 10 values:")
                    st.write(value_counts.head(10))
                    st.info(f"Showing 10 out of {len(value_counts)} unique values")
                else:
                    st.write(value_counts)
                
                # Create visualizations
                col1, col2 = st.columns(2)
                
                with col1:
                    # Bar chart
                    fig_bar = px.bar(
                        value_counts.head(10),
                        x=column,
                        y='Count',
                        title=f"Top values in {column}",
                        color_discrete_sequence=['#4F8BF9']
                    )
                    st.plotly_chart(fig_bar, use_container_width=True)
                
                with col2:
                    # Pie chart
                    fig_pie = px.pie(
                        value_counts.head(10),
                        names=column,
                        values='Count',
                        title=f"Proportion of top values in {column}",
                        color_discrete_sequence=px.colors.qualitative.Plotly
                    )
                    st.plotly_chart(fig_pie, use_container_width=True)
                
                # Text analysis if it's a text column
                if df[column].dtype == 'object':
                    # Check if it contains long text
                    avg_length = df[column].astype(str).str.len().mean()
                    
                    if avg_length > 20:  # Assume it's text if average length > 20 chars
                        st.markdown("### Text Analysis")
                        
                        # Word count
                        df_text = df.copy()
                        df_text['word_count'] = df[column].astype(str).str.split().str.len()
                        
                        # Word count distribution
                        fig_wc = px.histogram(
                            df_text,
                            x='word_count',
                            title="Word Count Distribution",
                            color_discrete_sequence=['#4F8BF9']
                        )
                        st.plotly_chart(fig_wc, use_container_width=True)
                        
                        # Most common words
                        import re
                        from collections import Counter
                        
                        # Combine all text and extract words
                        all_text = " ".join(df[column].astype(str).dropna())
                        words = re.findall(r'\b\w+\b', all_text.lower())
                        
                        # Remove common stop words
                        stop_words = {'a', 'an', 'the', 'and', 'or', 'but', 'is', 'are', 'in', 'to', 'of', 'for', 'with', 'on', 'at', 'this', 'that'}
                        words = [word for word in words if word not in stop_words]
                        
                        # Count words
                        word_counts = Counter(words).most_common(20)
                        
                        # Display as bar chart
                        word_df = pd.DataFrame(word_counts, columns=['Word', 'Count'])
                        
                        fig_words = px.bar(
                            word_df,
                            x='Word',
                            y='Count',
                            title="Most Common Words",
                            color_discrete_sequence=['#4F8BF9']
                        )
                        st.plotly_chart(fig_words, use_container_width=True)
    
    # Relationship Analysis
    elif analysis_type == "Relationship Analysis":
        st.markdown("### Analyze Relationships Between Variables")
        
        # Select columns to analyze
        col1, col2 = st.columns(2)
        
        with col1:
            x_column = st.selectbox("Select X variable", df.columns.tolist(), key="x_var")
        
        with col2:
            # Filter y options to exclude x
            y_options = [col for col in df.columns if col != x_column]
            y_column = st.selectbox("Select Y variable", y_options, key="y_var")
        
        # Optional color variable
        color_column = st.selectbox(
            "Color by (optional)",
            ["None"] + [col for col in df.columns if col not in [x_column, y_column]],
            key="color_var"
        )
        
        color_column = None if color_column == "None" else color_column
        
        if x_column and y_column:
            st.markdown(f"### Relationship between {x_column} and {y_column}")
            
            # Determine the plot type based on data types
            x_is_numeric = pd.api.types.is_numeric_dtype(df[x_column])
            y_is_numeric = pd.api.types.is_numeric_dtype(df[y_column])
            x_is_datetime = pd.api.types.is_datetime64_dtype(df[x_column])
            y_is_datetime = pd.api.types.is_datetime64_dtype(df[y_column])
            x_is_categorical = not (x_is_numeric or x_is_datetime)
            y_is_categorical = not (y_is_numeric or y_is_datetime)
            
            if x_is_numeric and y_is_numeric:
                # Both numeric - scatter plot
                fig = px.scatter(
                    df,
                    x=x_column,
                    y=y_column,
                    color=color_column,
                    title=f"{y_column} vs {x_column}",
                    opacity=0.7,
                    trendline="ols" if color_column is None else None
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Calculate correlation
                correlation = df[[x_column, y_column]].corr().iloc[0, 1]
                st.markdown(f"**Correlation coefficient:** {correlation:.4f}")
                
                # Interpret correlation
                if abs(correlation) > 0.7:
                    strength = "strong"
                elif abs(correlation) > 0.3:
                    strength = "moderate"
                else:
                    strength = "weak"
                
                direction = "positive" if correlation > 0 else "negative"
                
                st.markdown(f"There is a **{strength} {direction}** correlation between {x_column} and {y_column}.")
                
                # Add statistical significance test
                from scipy import stats as scipy_stats
                
                # Remove NaN values
                df_clean = df[[x_column, y_column]].dropna()
                
                if len(df_clean) > 2:  # Need at least 3 points for statistical testing
                    r, p_value = scipy_stats.pearsonr(df_clean[x_column], df_clean[y_column])
                    
                    st.markdown(f"**Statistical significance:** p-value = {p_value:.4f}")
                    
                    if p_value < 0.05:
                        st.markdown("The correlation is statistically significant (p < 0.05).")
                    else:
                        st.markdown("The correlation is not statistically significant (p >= 0.05).")
            
            elif (x_is_datetime and y_is_numeric) or (y_is_datetime and x_is_numeric):
                # Time series - line plot
                date_col = x_column if x_is_datetime else y_column
                value_col = y_column if x_is_datetime else x_column
                
                fig = px.line(
                    df,
                    x=date_col,
                    y=value_col,
                    color=color_column,
                    title=f"{value_col} over time",
                    markers=True
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Trend analysis
                if color_column is None:
                    # Sort by date
                    df_sorted = df.sort_values(by=date_col)
                    
                    # Calculate rolling average
                    window = min(30, len(df) // 5)  # Reasonable window size
                    if window >= 3:  # Need at least 3 points for rolling average
                        df_sorted['rolling_avg'] = df_sorted[value_col].rolling(window=window).mean()
                        
                        fig_trend = px.line(
                            df_sorted,
                            x=date_col,
                            y=[value_col, 'rolling_avg'],
                            title=f"{value_col} with {window}-point Rolling Average",
                            labels={'value': value_col, 'variable': 'Series'}
                        )
                        
                        fig_trend.update_traces(line=dict(color='lightgrey'), selector=dict(name=value_col))
                        fig_trend.update_traces(line=dict(color='red', width=3), selector=dict(name='rolling_avg'))
                        
                        st.plotly_chart(fig_trend, use_container_width=True)
            
            elif x_is_categorical and y_is_numeric:
                # Categorical vs Numeric - box plot and bar chart
                col1, col2 = st.columns(2)
                
                with col1:
                    # Box plot
                    fig_box = px.box(
                        df,
                        x=x_column,
                        y=y_column,
                        color=color_column,
                        title=f"{y_column} by {x_column} (Box Plot)",
                        notched=True
                    )
                    st.plotly_chart(fig_box, use_container_width=True)
                
                with col2:
                    # Bar chart (average)
                    agg_df = df.groupby(x_column)[y_column].mean().reset_index()
                    
                    fig_bar = px.bar(
                        agg_df,
                        x=x_column,
                        y=y_column,
                        title=f"Average {y_column} by {x_column}",
                        color_discrete_sequence=['#4F8BF9']
                    )
                    st.plotly_chart(fig_bar, use_container_width=True)
                
                # ANOVA test for significant differences
                if color_column is None:
                    from scipy import stats as scipy_stats
                    
                    # Get groups (dropping NaN values)
                    groups = [df[df[x_column] == val][y_column].dropna() for val in df[x_column].unique()]
                    groups = [group for group in groups if len(group) > 0]  # Remove empty groups
                    
                    if len(groups) >= 2:  # Need at least 2 groups
                        f_stat, p_value = scipy_stats.f_oneway(*groups)
                        
                        st.markdown(f"**ANOVA Test:** F-statistic = {f_stat:.4f}, p-value = {p_value:.4f}")
                        
                        if p_value < 0.05:
                            st.markdown(f"There are statistically significant differences in {y_column} between {x_column} groups (p < 0.05).")
                        else:
                            st.markdown(f"There are no statistically significant differences in {y_column} between {x_column} groups (p >= 0.05).")
            
            elif y_is_categorical and x_is_numeric:
                # Same as above but with x and y flipped
                col1, col2 = st.columns(2)
                
                with col1:
                    # Box plot
                    fig_box = px.box(
                        df,
                        y=y_column,
                        x=x_column,
                        color=color_column,
                        title=f"{x_column} by {y_column} (Box Plot)",
                        notched=True
                    )
                    st.plotly_chart(fig_box, use_container_width=True)
                
                with col2:
                    # Bar chart (average)
                    agg_df = df.groupby(y_column)[x_column].mean().reset_index()
                    
                    fig_bar = px.bar(
                        agg_df,
                        y=y_column,
                        x=x_column,
                        title=f"Average {x_column} by {y_column}",
                        orientation='h',
                        color_discrete_sequence=['#4F8BF9']
                    )
                    st.plotly_chart(fig_bar, use_container_width=True)
                
                # ANOVA test
                if color_column is None:
                    from scipy import stats as scipy_stats
                    
                    # Get groups (dropping NaN values)
                    groups = [df[df[y_column] == val][x_column].dropna() for val in df[y_column].unique()]
                    groups = [group for group in groups if len(group) > 0]  # Remove empty groups
                    
                    if len(groups) >= 2:  # Need at least 2 groups
                        f_stat, p_value = scipy_stats.f_oneway(*groups)
                        
                        st.markdown(f"**ANOVA Test:** F-statistic = {f_stat:.4f}, p-value = {p_value:.4f}")
                        
                        if p_value < 0.05:
                            st.markdown(f"There are statistically significant differences in {x_column} between {y_column} groups (p < 0.05).")
                        else:
                            st.markdown(f"There are no statistically significant differences in {x_column} between {y_column} groups (p >= 0.05).")
            
            elif x_is_categorical and y_is_categorical:
                # Both categorical - contingency table and mosaic plot
                
                # Create contingency table
                contingency = pd.crosstab(df[y_column], df[x_column])
                
                # Display the table
                st.markdown("**Contingency Table:**")
                st.write(contingency)
                
                # Create heatmap
                fig_heatmap = px.imshow(
                    contingency,
                    title=f"Relationship between {x_column} and {y_column}",
                    color_continuous_scale='RdBu_r',
                    aspect='auto'
                )
                
                st.plotly_chart(fig_heatmap, use_container_width=True)
                
                # Chi-square test for independence
                from scipy import stats as scipy_stats
                
                chi2, p_value, dof, expected = scipy_stats.chi2_contingency(contingency)
                
                st.markdown(f"**Chi-square Test:** chiÂ² = {chi2:.4f}, p-value = {p_value:.4f}, df = {dof}")
                
                if p_value < 0.05:
                    st.markdown(f"There is a statistically significant association between {x_column} and {y_column} (p < 0.05).")
                else:
                    st.markdown(f"There is no statistically significant association between {x_column} and {y_column} (p >= 0.05).")
    
    # Group Comparison
    elif analysis_type == "Group Comparison":
        st.markdown("### Compare Groups in Your Data")
        
        # Select grouping variable
        group_column = st.selectbox("Select grouping variable", df.columns.tolist(), key="group_var")
        
        if group_column:
            # Get unique groups
            groups = df[group_column].unique()
            
            if len(groups) > 10:
                st.warning(f"There are {len(groups)} unique values in {group_column}. Analysis will be limited to the top 10 most frequent groups.")
                # Get top 10 most frequent groups
                top_groups = df[group_column].value_counts().head(10).index.tolist()
                groups = top_groups
            
            # Select variables to compare
            compare_columns = st.multiselect(
                "Select variables to compare across groups",
                [col for col in df.columns if col != group_column],
                key="compare_vars"
            )
            
            if compare_columns:
                st.markdown(f"### Comparing {', '.join(compare_columns)} across {group_column} groups")
                
                # Create comparison visualizations for each selected column
                for column in compare_columns:
                    st.markdown(f"#### {column} by {group_column}")
                    
                    # Different visualizations based on column type
                    if pd.api.types.is_numeric_dtype(df[column]):
                        # Numeric column - box plot and bar chart
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            # Box plot
                            fig_box = px.box(
                                df[df[group_column].isin(groups)],
                                x=group_column,
                                y=column,
                                title=f"{column} Distribution by {group_column}",
                                notched=True
                            )
                            st.plotly_chart(fig_box, use_container_width=True)
                        
                        with col2:
                            # Bar chart (average)
                            agg_df = df[df[group_column].isin(groups)].groupby(group_column)[column].mean().reset_index()
                            
                            fig_bar = px.bar(
                                agg_df,
                                x=group_column,
                                y=column,
                                title=f"Average {column} by {group_column}",
                                color_discrete_sequence=['#4F8BF9']
                            )
                            st.plotly_chart(fig_bar, use_container_width=True)
                        
                        # ANOVA test
                        from scipy import stats as scipy_stats
                        
                        # Get groups (dropping NaN values)
                        data_groups = [df[df[group_column] == val][column].dropna() for val in groups]
                        data_groups = [group for group in data_groups if len(group) > 0]  # Remove empty groups
                        
                        if len(data_groups) >= 2:  # Need at least 2 groups
                            try:
                                f_stat, p_value = scipy_stats.f_oneway(*data_groups)
                                
                                st.markdown(f"**ANOVA Test:** F-statistic = {f_stat:.4f}, p-value = {p_value:.4f}")
                                
                                if p_value < 0.05:
                                    st.markdown(f"There are statistically significant differences in {column} between {group_column} groups (p < 0.05).")
                                else:
                                    st.markdown(f"There are no statistically significant differences in {column} between {group_column} groups (p >= 0.05).")
                            except:
                                st.warning("Could not perform ANOVA test. This may be due to insufficient data in some groups.")
                    
                    elif pd.api.types.is_datetime64_dtype(df[column]):
                        # Datetime column - timeline plot
                        fig_timeline = px.scatter(
                            df[df[group_column].isin(groups)],
                            x=column,
                            y=group_column,
                            title=f"{column} Timeline by {group_column}",
                            color=group_column
                        )
                        
                        st.plotly_chart(fig_timeline, use_container_width=True)
                        
                        # Summary statistics
                        summary = df[df[group_column].isin(groups)].groupby(group_column)[column].agg(['min', 'max']).reset_index()
                        summary['range_days'] = (summary['max'] - summary['min']).dt.days
                        
                        st.markdown("**Date Range Summary:**")
                        st.write(summary)
                    
                    else:
                        # Categorical column - stacked bar chart
                        # Create cross-tabulation
                        cross_tab = pd.crosstab(df[group_column], df[column], normalize='index') * 100
                        
                        # Limit to selected groups
                        cross_tab = cross_tab.loc[cross_tab.index.isin(groups)]
                        
                        # Create stacked bar chart
                        fig_stacked = px.bar(
                            cross_tab,
                            barmode='stack',
                            title=f"{column} Distribution by {group_column} (%)",
                            color_discrete_sequence=px.colors.qualitative.Plotly
                        )
                        
                        st.plotly_chart(fig_stacked, use_container_width=True)
                        
                        # Chi-square test
                        from scipy import stats as scipy_stats
                        
                        # Create contingency table for chi-square
                        contingency = pd.crosstab(df[df[group_column].isin(groups)][group_column], 
                                                df[df[group_column].isin(groups)][column])
                        
                        # Calculate chi-square if possible
                        if contingency.shape[0] >= 2 and contingency.shape[1] >= 2:
                            try:
                                chi2, p_value, dof, expected = scipy_stats.chi2_contingency(contingency)
                                
                                st.markdown(f"**Chi-square Test:** chiÂ² = {chi2:.4f}, p-value = {p_value:.4f}, df = {dof}")
                                
                                if p_value < 0.05:
                                    st.markdown(f"There is a statistically significant association between {group_column} and {column} (p < 0.05).")
                                else:
                                    st.markdown(f"There is no statistically significant association between {group_column} and {column} (p >= 0.05).")
                            except:
                                st.warning("Could not perform Chi-square test. This may be due to insufficient data in some groups.")
    
    # Time Series Decomposition
    elif analysis_type == "Time Series Decomposition":
        st.markdown("### Time Series Analysis and Decomposition")
        
        # Find datetime columns
        date_cols = df.select_dtypes(include=['datetime']).columns.tolist()
        
        # Also check for columns that might be dates but not detected
        potential_date_cols = []
        for col in df.columns:
            if col not in date_cols:
                # Check if column has string data
                if df[col].dtype == 'object':
                    # Take a sample and try to convert to datetime
                    sample = df[col].dropna().head(5)
                    try:
                        pd.to_datetime(sample, errors='raise')
                        potential_date_cols.append(col)
                    except:
                        pass
        
        # Combine both lists
        all_date_cols = date_cols + potential_date_cols
        
        if not all_date_cols:
            st.info("No datetime columns or potential date columns found in the dataset. Time series analysis requires a date column.")
        else:
            # Select a date column
            date_column = st.selectbox("Select date column", all_date_cols, key="date_col")
            
            # Convert to datetime if not already
            if date_column in potential_date_cols:
                with st.spinner("Converting to datetime format..."):
                    df_ts = df.copy()
                    try:
                        df_ts[date_column] = pd.to_datetime(df_ts[date_column])
                    except:
                        st.error(f"Could not convert {date_column} to datetime format.")
                        st.stop()
            else:
                df_ts = df.copy()
            
            # Select a value column
            numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
            
            if not numeric_cols:
                st.info("No numeric columns found for time series analysis.")
            else:
                value_column = st.selectbox("Select value column", numeric_cols, key="value_col")
                
                if date_column and value_column:
                    st.markdown(f"### Time Series Analysis: {value_column} over {date_column}")
                    
                    # Sort by date and check for duplicate dates
                    df_ts = df_ts.sort_values(by=date_column)
                    duplicated_dates = df_ts[date_column].duplicated().sum()
                    
                    if duplicated_dates > 0:
                        st.warning(f"Found {duplicated_dates} duplicate dates. Aggregating by {date_column} using mean.")
                        df_ts = df_ts.groupby(date_column)[value_column].mean().reset_index()
                    
                    # Check if enough data points
                    if len(df_ts) < 10:
                        st.error("Not enough data points for meaningful time series analysis. Need at least 10 data points.")
                    else:
                        # Create line plot
                        fig_line = px.line(
                            df_ts,
                            x=date_column,
                            y=value_column,
                            title=f"{value_column} over Time",
                            markers=True
                        )
                        
                        st.plotly_chart(fig_line, use_container_width=True)
                        
                        # Time series decomposition
                        try:
                            from statsmodels.tsa.seasonal import seasonal_decompose
                            
                            # Check for regular frequency
                            # Set date as index
                            df_ts_idx = df_ts.set_index(date_column)
                            
                            # Check if index is datetime
                            if not isinstance(df_ts_idx.index, pd.DatetimeIndex):
                                st.error("Index must be a DatetimeIndex for time series decomposition.")
                            else:
                                # Check the frequency of the time series
                                inferred_freq = pd.infer_freq(df_ts_idx.index)
                                
                                if inferred_freq is None:
                                    st.warning("Could not infer frequency from the data. Using daily frequency by default.")
                                    df_ts_idx = df_ts_idx.asfreq('D')
                                
                                # Decompose the time series
                                decomposition = seasonal_decompose(df_ts_idx[value_column], model='additive')
                                
                                # Create plots for trend, seasonal, and residual components
                                trend = decomposition.trend
                                seasonal = decomposition.seasonal
                                residual = decomposition.resid
                                
                                # Create subplots
                                fig = make_subplots(
                                    rows=4, 
                                    cols=1,
                                    subplot_titles=("Original", "Trend", "Seasonality", "Residuals"),
                                    vertical_spacing=0.1
                                )
                                
                                # Add traces
                                fig.add_trace(
                                    go.Scatter(x=df_ts_idx.index, y=df_ts_idx[value_column], mode='lines', name='Original'),
                                    row=1, col=1
                                )
                                
                                fig.add_trace(
                                    go.Scatter(x=trend.index, y=trend, mode='lines', name='Trend', line=dict(color='red')),
                                    row=2, col=1
                                )
                                
                                fig.add_trace(
                                    go.Scatter(x=seasonal.index, y=seasonal, mode='lines', name='Seasonal', line=dict(color='green')),
                                    row=3, col=1
                                )
                                
                                fig.add_trace(
                                    go.Scatter(x=residual.index, y=residual, mode='lines', name='Residual', line=dict(color='purple')),
                                    row=4, col=1
                                )
                                
                                # Update layout
                                fig.update_layout(
                                    height=800,
                                    title=f"Time Series Decomposition of {value_column}",
                                    showlegend=False
                                )
                                
                                st.plotly_chart(fig, use_container_width=True)
                                
                                # Explain the components
                                st.markdown("""
                                ### Interpretation of Time Series Components
                                
                                - **Trend**: The long-term progression of the series (upward or downward)
                                - **Seasonality**: The repeating short-term cycle in the series
                                - **Residual**: The random variation in the series (what remains after removing trend and seasonality)
                                """)
                                
                                # Calculate ACF and PACF
                                from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
                                import matplotlib.pyplot as plt
                                
                                # Create matplotlib figures
                                fig_acf, ax_acf = plt.subplots(figsize=(10, 4))
                                fig_pacf, ax_pacf = plt.subplots(figsize=(10, 4))
                                
                                # Plot ACF and PACF
                                plot_acf(df_ts_idx[value_column].dropna(), ax=ax_acf, lags=20)
                                plot_pacf(df_ts_idx[value_column].dropna(), ax=ax_pacf, lags=20)
                                
                                # Display plots
                                st.markdown("### Autocorrelation and Partial Autocorrelation")
                                st.markdown("""
                                These plots help identify patterns and determine appropriate parameters for time series models:
                                - **ACF (Autocorrelation Function)**: Shows correlation between a time series and its lagged values
                                - **PACF (Partial Autocorrelation Function)**: Shows correlation between a time series and its lagged values after removing effects of intermediate lags
                                """)
                                
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.pyplot(fig_acf)
                                with col2:
                                    st.pyplot(fig_pacf)
                                
                        except Exception as e:
                            st.error(f"Error in time series decomposition: {str(e)}")
                            st.info("Time series decomposition requires regularly spaced data. Your data might not have a consistent time interval.")

# Navigation buttons
st.markdown("---")
col1, col2 = st.columns(2)

with col1:
    if st.button("â† Back to Data Transformation", key="back_to_transform"):
        st.switch_page("pages/04_Data_Transformation.py")

with col2:
    if st.button("Continue to Export Reports â†’", key="continue_to_export"):
        st.switch_page("pages/06_Export_Reports.py")

# Add a sidebar with explanations
with st.sidebar:
    st.header("Understanding Data Insights")
    
    st.markdown("""
    ### What are Data Insights?
    
    Data insights are significant findings and patterns discovered in your data that provide valuable information for decision-making.
    
    ### How Insights are Generated
    
    Our AI analyzes your dataset looking for:
    
    - **Correlations**: Relationships between variables
    - **Outliers**: Unusual values that may be significant
    - **Patterns**: Repeated behaviors or trends
    - **Anomalies**: Unexpected data points or distributions
    - **Opportunities**: Potential actions to improve outcomes
    
    ### Using Insights Effectively
    
    1. **Review all insights** and focus on those with high importance ratings
    
    2. **Ask follow-up questions** in the "Ask Questions" tab
    
    3. **Use the custom analysis** tools to dig deeper into interesting findings
    
    4. **Export insights** to share with your team
    """)
    
    st.markdown("---")
    
    st.markdown("""
    **Remember**: The insights are generated based on the data provided. 
    The quality and completeness of your data determines the value of the insights.
    """)
